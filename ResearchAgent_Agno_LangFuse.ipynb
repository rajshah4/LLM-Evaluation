{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02-H04579t8u"
      },
      "source": [
        "# Building a Research Agent using Agno\n",
        "\n",
        "This notebook demonstrates how to build and use a **Research Agent** leveraging the [Agno framework](https://github.com/agno-agi/agno) alongside tools like [Tavily](https://github.com/tavily-ai/tavily-python) for web search and the [Contextual AI](https://contextual.ai/) for RAG search.  \n",
        "\n",
        "The workflow is organized into three major sections, each designed to progressively introduce you to agent construction, reasoning, and advanced tool integration.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Setup the Environment\n",
        "\n",
        "**Learn how to set up your environment and verify connectivity with essential research tools.**  \n",
        "- **1.0 Setup the Environment:**  \n",
        "  Install and configure all required packages and dependencies for Agno and Contextual AI.\n",
        "- **1.1 Test Tooling Connectivity:**  \n",
        "  Ensure that external tools are accessible and working, including:\n",
        "  - *Tavily (Web Search):* For real-time web information retrieval.\n",
        "  - *Contextual AI (RAG Agent):* For retrieval-augmented generation and document-based answers.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Build a Simple Agent with Reasoning\n",
        "\n",
        "**Create basic research agents powered by leading LLMs.**  \n",
        "- **2.0 Claude 3.7:**  \n",
        "  Build a simple agent using Anthropic's Claude 3.7 model for general reasoning tasks.\n",
        "- **2.1 OpenAI o4-mini:**  \n",
        "  Construct an agent using OpenAI's o4-mini model for general reasoning tasks.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Build a Research Agent with Reasoning and Tool Use\n",
        "\n",
        "**Combine LLMs with external tools for advanced, auditable research workflows.**  \n",
        "- **3.0 Configure Tooling for Agents:**  \n",
        "  Set up and register external tools for agent use.\n",
        "- **3.1 Research Agents with Tools:**  \n",
        "  Explore advanced agents that leverage both LLMs and tools:\n",
        "  - *Claude 3.7 with Web Search:* Integrate web search for up-to-date information.\n",
        "  - *Claude 3.7 with RAG Search:* Use retrieval-augmented generation for document-grounded answers.\n",
        "  - *OpenAI o4-mini:* Combine OpenAI's model with tool-augmented reasoning.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Features Demonstrated\n",
        "\n",
        "- **Tool-Augmented Reasoning:**  \n",
        "  Empower agents to use both language models and external tools (like ContextualAI RAG search and web search)\n",
        "\n",
        "- **Modular Agent Construction:**  \n",
        "  Build agents step-by-step, starting from simple reasoning agents to advanced research agents with integrated tool use\n",
        "\n",
        "- **Step-by-Step Debugging:**  \n",
        "  Access detailed debug outputs, including intermediate reasoning steps, tool calls, and results, to better understand and audit the agent's decision-making process.\n",
        "\n",
        "---\n",
        "\n",
        "You can run this notebook entirely in Colab:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rajshah4/LLM-Evaluation/blob/main/ResearchAgent_Agno_LangFuse.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWm3zGBbAAC7"
      },
      "source": [
        "## 1.0 Setup the Environment\n",
        "\n",
        "### Installing Required Packages\n",
        "\n",
        "We will install the latest versions of all required libraries.  \n",
        "- `agno`, `anthropic`, and `openai` are for building and running LLM agents.\n",
        "- `tavily-python` enables web search capabilities.\n",
        "- `contextual-client` is used for retrieval-augmented generation (RAG) with Contextual AI.\n",
        "\n",
        "If running in Colab, you may need to restart the runtime after installation for all packages to be properly recognized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hl_SZOPnndDh"
      },
      "outputs": [],
      "source": [
        "%pip install agno anthropic openai tavily-python contextual-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kUK0X9ynNSa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from textwrap import dedent\n",
        "\n",
        "import httpx\n",
        "from agno.agent import Agent\n",
        "from agno.models.anthropic import Claude\n",
        "from agno.tools.reasoning import ReasoningTools\n",
        "from agno.models.openai import OpenAIChat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgo9zSkykhqP"
      },
      "source": [
        "## 1.1 Setting Up API Keys and Clients\n",
        "\n",
        "In this cell, we set up API keys for OpenAI, Anthropic, Tavily, and ContextualAI.  \n",
        "**Important:** Replace the placeholder API keys with your own credentials.\n",
        "\n",
        "We then instantiate the clients for:\n",
        "- `ContextualAI` (for RAG/document search) - [Get Key](https://app.contextual.ai/)\n",
        "- `TavilyClient` (for web search) - [Get Key](https://app.tavily.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjkWQHuXkg_q"
      },
      "outputs": [],
      "source": [
        "# Set OpenAI API key as environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-z\"\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-\"\n",
        "os.environ[\"CONTEXTUAL_API_KEY\"] = \"key-EMNM\"\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"tvly-dev-\"\n",
        "\n",
        "from contextual import ContextualAI\n",
        "client = ContextualAI()\n",
        "\n",
        "from tavily import TavilyClient\n",
        "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRQgWBmfpkyM"
      },
      "source": [
        "## 1.2 Test the tooling connectivity\n",
        "Let's make sure our tools work before we connect them up to our agents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jewW6qJwAKsS"
      },
      "source": [
        "#### Tavily (Web Search)\n",
        "\n",
        "Let's verify that the Tavily web search API is working.  \n",
        "A successful response should return a summary or relevant information about the query.  \n",
        "If you get an error, check your API key and internet connection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QPhFxWzogL6"
      },
      "outputs": [],
      "source": [
        "response = tavily_client.search(\"Who is Leo Messi?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvZWbBUzpxZz"
      },
      "source": [
        "#### Contextual AI (RAG Agent)\n",
        "\n",
        "Now, let's test the ContextualAI RAG agent by querying for Tesla's R&D expenses.  \n",
        "A successful response should return a relevant answer based on indexed documents.  \n",
        "If you get an error, ensure your API key is correct and the agent ID is valid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpXWmFB1oam8"
      },
      "outputs": [],
      "source": [
        "agent_id = 'c25462d9-f564-4a24-b390-d900ae59b67d'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2Jrcac9AKR2"
      },
      "outputs": [],
      "source": [
        "query_result = client.agents.query.create(\n",
        "    agent_id=agent_id,\n",
        "    messages=[{\n",
        "        # Input your question here\n",
        "        \"content\": \"tesla R&D expenses\",\n",
        "        \"role\": \"user\"\n",
        "    }]\n",
        ")\n",
        "query_result.message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOxjaakzANCV"
      },
      "source": [
        "# Build a Simple Agent with Reasoning\n",
        "\n",
        "Let's start with a simple agent using reasoning as a way to make sure our agents/APIs are working properly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg81EQ9hZsY7"
      },
      "source": [
        "### 2.0 Claude 3.7\n",
        "\n",
        "Here, we instantiate a basic research agent using Anthropic's Claude 3.7 model. To show the effect of reasoning, we will try it with and without reasoning.\n",
        "This agent will answer a general knowledge question and display its reasoning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijFuPKVnZanQ"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"I own a boutique hotel chain with locations in Lisbon, Berlin, and London. I plan to expand into a new country in Europe, and a city in Asia, in 2026. What factorsâ€”such as tourism growth, seasonal occupancy patterns, and local economic indicatorsâ€”best predict success? I want to be ahead of the curve and be in the next hot city before others. Pull regional travel data, economic statistics, and hotel occupancy rates; analyze trends visually and recommend ideal expansion locations.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaoouifcX283"
      },
      "outputs": [],
      "source": [
        "cl_agent = Agent(\n",
        "    model=Claude(id=\"claude-3-7-sonnet-latest\"),\n",
        "    markdown=True,\n",
        "    reasoning=False,\n",
        ")\n",
        "\n",
        "cl_agent.print_response(query,stream=True,show_full_reasoning=True,stream_intermediate_steps=True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwMbaFcv9sRT"
      },
      "outputs": [],
      "source": [
        "cl_agent_r = Agent(\n",
        "    model=Claude(id=\"claude-3-7-sonnet-latest\"),\n",
        "    markdown=True,\n",
        "    reasoning=True,\n",
        ")\n",
        "\n",
        "#Easier to process the outputs this way\n",
        "cl_agent_r.print_response(query,stream=True,show_full_reasoning=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3PUTc_wql9-"
      },
      "source": [
        "### 2.1 OpenAI o4-mini\n",
        "\n",
        "Now, we create a similar agent using OpenAI's o4-mini model.  \n",
        "This demonstrates how you can easily swap out LLMs in the Agno framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KI5iZJNqsHd"
      },
      "outputs": [],
      "source": [
        "agent_o4 = Agent(\n",
        "    model=OpenAIChat(id=\"o4-mini\"),\n",
        "    markdown=True,\n",
        "    reasoning=True,\n",
        ")\n",
        "\n",
        "agent_o4.print_response(query,stream=True,show_full_reasoning=True,stream_intermediate_steps=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr_5TMTL1ppO"
      },
      "source": [
        "# Build a Research Agent with Reasoning and Tool Use\n",
        "\n",
        "Let's get an agent working that can answer questions by searching the web or retrieving information via a RAG query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov3jw3Ir-d0F"
      },
      "source": [
        "## 3.0 Configure the Tooling for Agents\n",
        "\n",
        "Next, we'll setup the tools to work with our agentic frameworks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq6DQeUWlY3G"
      },
      "source": [
        "### Defining a ContextualAI RAG Search Tool\n",
        "\n",
        "This function allows the agent to query the ContextualAI RAG agent for answers grounded in indexed documents (e.g., SEC filings, financial reports)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFEbC_34skKq"
      },
      "outputs": [],
      "source": [
        "def get_contextual_results(query: str) -> str:\n",
        "    \"\"\"Search financial 10k and 10q reports for technology companies, such as NVIDIA, and return the results.\n",
        "    Args: query (str): The query/question to ask the ContextualAI RAG agent.\n",
        "    Returns: str: The response content from the RAG agent.\n",
        "    \"\"\"\n",
        "    query_result = client.agents.query.create(\n",
        "        agent_id=agent_id,\n",
        "        messages=[{\n",
        "            \"content\": query,\n",
        "            \"role\": \"user\"\n",
        "        }]\n",
        "    )\n",
        "    return query_result.message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAffHONRs7dN"
      },
      "outputs": [],
      "source": [
        "get_contextual_results (\"What are Tesla's R&D expenses\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH9eqNACliTD"
      },
      "source": [
        "### Defining a Tavily Web Search Tool\n",
        "\n",
        "This function enables the agent to perform real-time web searches using Tavily, returning up-to-date information from the internet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6n4E0JVlsmmH"
      },
      "outputs": [],
      "source": [
        "def get_search_tavily(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Search for recent information using Tavily's search API.\n",
        "    Args: query (str): The search query\n",
        "    Returns: Dict containing the query and search results or error message\n",
        "    \"\"\"\n",
        "    search_result = tavily_client.search(\n",
        "        query=query,\n",
        "        search_depth=\"advanced\",\n",
        "        include_answer=True,\n",
        "        include_raw_content=False,\n",
        "        max_results=5\n",
        "    )\n",
        "    return json.dumps(search_result, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YknVHCr_t0jl"
      },
      "outputs": [],
      "source": [
        "get_search_tavily(\"What is the weather in Chicago\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVrZE0MK-muR"
      },
      "source": [
        "## 3.1 Research Agents with Tools\n",
        "\n",
        "We now combine LLMs with both RAG and web search tools.  \n",
        "This agent can answer questions by searching the web or retrieving information from indexed documents, providing more accurate and up-to-date answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRpvxbVW2GI0"
      },
      "source": [
        "#### Claude 3.7 with web search\n",
        "\n",
        "Let's test the agent with a real-world question.  \n",
        "The output will show the agent's reasoning steps and how it uses external tools to arrive at an answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmHJiE6G-Ly3"
      },
      "outputs": [],
      "source": [
        "reasoning_agent = Agent(\n",
        "    model=Claude(id=\"claude-3-7-sonnet-latest\"),\n",
        "    instructions=dedent(\"\"\"\n",
        "        You are a research analyst, I want you use your tools to answer the query,\n",
        "        you should not use your own knowledge, but only use the tools to answer the question.\n",
        "    \"\"\"),\n",
        "    tools=[\n",
        "        ReasoningTools(add_instructions=True),\n",
        "        get_contextual_results,\n",
        "        get_search_tavily\n",
        "    ],\n",
        "    show_tool_calls=True,debug_mode=False,markdown=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAe5MXniu_ow"
      },
      "outputs": [],
      "source": [
        "reasoning_agent.print_response(\"What should I wear tomorrow?\", stream=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HO-FNyO2P8x"
      },
      "source": [
        "#### Claude 3.7 with RAG search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGU_kNoPwmWw"
      },
      "outputs": [],
      "source": [
        "reasoning_agent.print_response(\"Analyze the financial effectiveness of NVIDA to Tesla in 2023, use only 10k and 10q\", stream=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZIO-QRH2SbU"
      },
      "source": [
        "#### OpenAI o4-mini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44UH7bemxymR"
      },
      "outputs": [],
      "source": [
        "reasoning_agent = Agent(\n",
        "    model=OpenAIChat(id=\"o4-mini\", reasoning_effort=\"high\"),\n",
        "    instructions=dedent(\"\"\"\n",
        "        You are a research analyst, I want you use your tools to answer the query,\n",
        "        you should not use your own knowledge, but only use the tools to answer the question.\n",
        "    \"\"\"),\n",
        "    tools=[\n",
        "        ReasoningTools(add_instructions=True),\n",
        "        get_contextual_results,\n",
        "        get_search_tavily\n",
        "    ],\n",
        "    show_tool_calls=True,debug_mode=False,markdown=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNHVnaqZx7ZK"
      },
      "outputs": [],
      "source": [
        "reasoning_agent.print_response(\"Analyze the financial effectiveness of NVIDA to Tesla in 2023, use only 10k and 10q\", stream=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvr_1l--l5k2"
      },
      "source": [
        "# (Optional) Connect the Research Agent to Langfuse\n",
        "\n",
        "[Langfuse](https://langfuse.com/) is an experiment management and observability platform for LLM applications.  \n",
        "Connecting your agent to Langfuse allows you to track, debug, and analyze agent behavior and performance over time.\n",
        "\n",
        "**Note:** This section is optional and intended for users who want to add observability and experiment tracking to their agent workflows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyxQXTXgifWM"
      },
      "source": [
        "Agno has added [code snippets](https://github.com/agno-agi/agno/tree/main/cookbook/observability) for connecting to experiment managent / tracking platforms like [Langfuse](https://langfuse.com/).\n",
        "\n",
        "You will want to move this code to the start of the notebook to get logging working properly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvMhr45OiDOq"
      },
      "outputs": [],
      "source": [
        "%pip install langfuse opentelemetry-sdk opentelemetry-exporter-otlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EySV7H8ficus"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import os\n",
        "\n",
        "from openinference.instrumentation.agno import AgnoInstrumentor\n",
        "from opentelemetry import trace as trace_api\n",
        "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
        "from opentelemetry.sdk.trace import TracerProvider\n",
        "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "\n",
        "LANGFUSE_PUBLIC_KEY = \"pk-lf-\"\n",
        "LANGFUSE_SECRET_KEY = \"sk-lf-\"\n",
        "LANGFUSE_AUTH = base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
        "\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = (\n",
        "    \"https://us.cloud.langfuse.com/api/public/otel\"  # ðŸ‡ºðŸ‡¸ US data region\n",
        ")\n",
        "# os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"]=\"https://cloud.langfuse.com/api/public/otel\" # ðŸ‡ªðŸ‡º EU data region\n",
        "# os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"]=\"http://localhost:3000/api/public/otel\" # ðŸ  Local deployment (>= v3.22.0)\n",
        "\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\"\n",
        "\n",
        "\n",
        "tracer_provider = TracerProvider()\n",
        "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))\n",
        "trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
        "\n",
        "# Start instrumenting agno\n",
        "AgnoInstrumentor().instrument()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8UtANeic4-"
      },
      "outputs": [],
      "source": [
        "## Test Query for Langfuse\n",
        "agent = Agent(\n",
        "    model=OpenAIChat(id=\"gpt-4o-mini\"),\n",
        "    markdown=True,\n",
        "    debug_mode=True,\n",
        ")\n",
        "\n",
        "agent.print_response(\"What is currently trending on Twitter?\",stream=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
